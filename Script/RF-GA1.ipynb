{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04723def-6455-469e-b737-d8544ccd34ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "dataset = pd.read_csv('Inputdata.csv')\n",
    "dataset.head()\n",
    "X = dataset.iloc[:,[3,4,5,6,7,8,9,10,11,12,13,14]].values\n",
    "y = dataset.iloc[:,[2]].values \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 70% train, 30% remaining\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42)  # Split remaining 30% equally\n",
    "\n",
    "# Apply Standard Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fitness function for GA\n",
    "def fitness_function(params, X_train, y_train, X_val, y_val):\n",
    "    n_estimators = int(params[0])\n",
    "    max_depth = int(params[1])\n",
    "    max_features = int(params[2])\n",
    "\n",
    "    model = RandomForestRegressor(n_estimators=n_estimators, \n",
    "                                  max_depth=max_depth, \n",
    "                                  max_features=max_features, \n",
    "                                  random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    return mean_squared_error(y_val, predictions)\n",
    "\n",
    "# Initialize population\n",
    "def initialize_population(pop_size, dim, lb, ub):\n",
    "    lb = np.array(lb)  # Convert lb to a numpy array\n",
    "    ub = np.array(ub)  # Convert ub to a numpy array\n",
    "    return np.random.rand(pop_size, dim) * (ub - lb) + lb\n",
    "\n",
    "# Select parents based on fitness\n",
    "def select_parents(population, fitness, num_parents):\n",
    "    parents_idx = np.argsort(fitness)[:num_parents]\n",
    "    return population[parents_idx, :]\n",
    "\n",
    "# Perform crossover between parents\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.zeros(offspring_size)\n",
    "    num_parents = parents.shape[0]\n",
    "    for k in range(offspring_size[0]):\n",
    "        parent1_idx = k % num_parents\n",
    "        parent2_idx = (k + 1) % num_parents\n",
    "        crossover_point = np.random.randint(1, offspring_size[1])\n",
    "        offspring[k, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "# Perform mutation\n",
    "def mutation(offspring, lb, ub, mutation_rate=0.2):\n",
    "    for i in range(offspring.shape[0]):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            gene_idx = np.random.randint(offspring.shape[1])\n",
    "            random_value = np.random.rand() * (ub[gene_idx] - lb[gene_idx]) + lb[gene_idx]\n",
    "            offspring[i, gene_idx] = random_value\n",
    "    return offspring\n",
    "\n",
    "# Genetic Algorithm for optimization\n",
    "def genetic_algorithm(fobj, X_train, y_train, X_val, y_val, lb, ub, dim, pop_size, num_generations, num_parents_mating):\n",
    "    population = initialize_population(pop_size, dim, lb, ub)\n",
    "    best_solution = None\n",
    "    best_fitness = float('inf')\n",
    "    convergence_curve = []\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        fitness = np.array([fobj(ind, X_train, y_train, X_val, y_val) for ind in population])\n",
    "        best_idx = np.argmin(fitness)\n",
    "        \n",
    "        if fitness[best_idx] < best_fitness:\n",
    "            best_fitness = fitness[best_idx]\n",
    "            best_solution = population[best_idx, :]\n",
    "\n",
    "        convergence_curve.append(best_fitness)\n",
    "        parents = select_parents(population, fitness, num_parents_mating)\n",
    "        offspring_crossover = crossover(parents, (pop_size - parents.shape[0], dim))\n",
    "        offspring_mutation = mutation(offspring_crossover, lb, ub)\n",
    "        population[:parents.shape[0], :] = parents\n",
    "        population[parents.shape[0]:, :] = offspring_mutation\n",
    "\n",
    "    return best_solution, best_fitness, convergence_curve\n",
    "\n",
    "# Define hyperparameter bounds\n",
    "lb = [100, 1, 1]  # Lower bounds for n_estimators, max_depth, max_features\n",
    "ub = [200, 20, 10]  # Upper bounds for n_estimators, max_depth, max_features\n",
    "dim = 3  # Number of hyperparameters\n",
    "pop_size = 40\n",
    "num_generations = 100\n",
    "num_parents_mating = 20\n",
    "\n",
    "# Run GA optimization\n",
    "best_solution, best_fitness, convergence_curve = genetic_algorithm(\n",
    "    fitness_function, X_train, y_train, X_val, y_val, lb, ub, dim, pop_size, num_generations, num_parents_mating\n",
    ")\n",
    "\n",
    "print(f\"Optimized hyperparameters: n_estimators={int(best_solution[0])}, max_depth={int(best_solution[1])}, max_features={int(best_solution[2])}\")\n",
    "print(f\"Minimum validation error: {best_fitness}\")\n",
    "\n",
    "# Train the best RandomForestRegressor on the full training set\n",
    "best_regressor = RandomForestRegressor(n_estimators=int(best_solution[0]), \n",
    "                                       max_depth=int(best_solution[1]), \n",
    "                                       max_features=int(best_solution[2]), \n",
    "                                       random_state=42)\n",
    "best_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate RandomForest performance on the test set\n",
    "test_score = best_regressor.score(X_test, y_test)\n",
    "print(f\"R-squared on test set with best parameters: {test_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
